{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cord19 Embeddings with Keras.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamSiadati/Health/blob/master/Cord19_Embeddings_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:34.793339Z",
          "iopub.status.busy": "2020-10-02T11:26:34.792667Z",
          "iopub.status.idle": "2020-10-02T11:26:41.967480Z",
          "shell.execute_reply": "2020-10-02T11:26:41.966888Z"
        },
        "id": "Ym2nXOPuPV__"
      },
      "source": [
        "import functools\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tqdm import trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VgRRf2I7tER"
      },
      "source": [
        "# Analyze the embeddings\n",
        "\n",
        "Let's start off by analyzing the embedding by calculating and plotting a correlation matrix between different terms. If the embedding learned to successfully capture the meaning of different words, the embedding vectors of semantically similar words should be close together. Let's take a look at some COVID-19 related terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:41.973413Z",
          "iopub.status.busy": "2020-10-02T11:26:41.972756Z",
          "iopub.status.idle": "2020-10-02T11:26:46.866986Z",
          "shell.execute_reply": "2020-10-02T11:26:46.867430Z"
        },
        "id": "HNN_9bBKSLHU"
      },
      "source": [
        "# Use the inner product between two embedding vectors as the similarity measure\n",
        "def plot_correlation(labels, features):\n",
        "  corr = np.inner(features, features)\n",
        "  corr /= np.max(corr)\n",
        "  sns.heatmap(corr, xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "# Generate embeddings for some terms\n",
        "queries = [\n",
        "  # Related viruses\n",
        "  'coronavirus', 'SARS', 'MERS',\n",
        "  # Regions\n",
        "  'Italy', 'Spain', 'Europe',\n",
        "  # Symptoms\n",
        "  'cough', 'fever', 'throat'\n",
        "]\n",
        "\n",
        "module = hub.load('https://tfhub.dev/tensorflow/cord-19/swivel-128d/3')\n",
        "embeddings = module(queries)\n",
        "\n",
        "plot_correlation(queries, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg-PGqtm8B7K"
      },
      "source": [
        "We can see that the embedding successfully captured the meaning of the different terms. Each word is similar to the other words of its cluster (i.e. \"coronavirus\" highly correlates with \"SARS\" and \"MERS\"), while they are different from terms of other clusters (i.e. the similarity between \"SARS\" and \"Spain\" is close to 0).\n",
        "\n",
        "Now let's see how we can use these embeddings to solve a specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJ1jFmH7xMa"
      },
      "source": [
        "## SciCite: Citation Intent Classification\n",
        "\n",
        "This section shows how one can use the embedding for downstream tasks such as text classification. We'll use the [SciCite dataset](https://www.tensorflow.org/datasets/catalog/scicite) from TensorFlow Datasets to classify citation intents in academic papers. Given a sentence with a citation from an academic paper, classify whether the main intent of the citation is as background information, use of methods, or comparing results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:46.878623Z",
          "iopub.status.busy": "2020-10-02T11:26:46.876959Z",
          "iopub.status.idle": "2020-10-02T11:26:47.083680Z",
          "shell.execute_reply": "2020-10-02T11:26:47.084136Z"
        },
        "id": "Ghc-CzT8DDaZ"
      },
      "source": [
        "builder = tfds.builder(name='scicite')\n",
        "builder.download_and_prepare()\n",
        "train_data, validation_data, test_data = builder.as_dataset(\n",
        "    split=('train', 'validation', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:47.091759Z",
          "iopub.status.busy": "2020-10-02T11:26:47.090630Z",
          "iopub.status.idle": "2020-10-02T11:26:47.154988Z",
          "shell.execute_reply": "2020-10-02T11:26:47.155469Z"
        },
        "id": "CVjyBD0ZPh4Z"
      },
      "source": [
        "#@title Let's take a look at a few labeled examples from the training set\n",
        "NUM_EXAMPLES =   7#@param {type:\"integer\"}\n",
        "\n",
        "TEXT_FEATURE_NAME = builder.info.supervised_keys[0]\n",
        "LABEL_NAME = builder.info.supervised_keys[1]\n",
        "\n",
        "def label2str(numeric_label):\n",
        "  m = builder.info.features[LABEL_NAME].names\n",
        "  return m[numeric_label]\n",
        "\n",
        "data = next(iter(train_data.batch(NUM_EXAMPLES)))\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    TEXT_FEATURE_NAME: [ex.numpy().decode('utf8') for ex in data[0]],\n",
        "    LABEL_NAME: [label2str(x) for x in data[1]]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65s9UpYJ_1ct"
      },
      "source": [
        "## Training a citaton intent classifier\n",
        "\n",
        "We'll train a classifier on the [SciCite dataset](https://www.tensorflow.org/datasets/catalog/scicite) using Keras.  Let's build a model which use the CORD-19 embeddings with a classification layer on top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:47.165764Z",
          "iopub.status.busy": "2020-10-02T11:26:47.161189Z",
          "iopub.status.idle": "2020-10-02T11:26:48.133191Z",
          "shell.execute_reply": "2020-10-02T11:26:48.132673Z"
        },
        "id": "yZUclu8xBYlj"
      },
      "source": [
        "#@title Hyperparameters { run: \"auto\" }\n",
        "\n",
        "EMBEDDING = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/3'  #@param {type: \"string\"}\n",
        "TRAINABLE_MODULE = False  #@param {type: \"boolean\"}\n",
        "\n",
        "hub_layer = hub.KerasLayer(EMBEDDING, input_shape=[], \n",
        "                           dtype=tf.string, trainable=TRAINABLE_MODULE)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(3))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weZKWK-pLBll"
      },
      "source": [
        "## Train and evaluate the model\n",
        "\n",
        "Let's train and evaluate the model to see the performance on the SciCite task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:26:48.138599Z",
          "iopub.status.busy": "2020-10-02T11:26:48.137936Z",
          "iopub.status.idle": "2020-10-02T11:27:39.655852Z",
          "shell.execute_reply": "2020-10-02T11:27:39.656322Z"
        },
        "id": "cO1FWkZW2WS9"
      },
      "source": [
        "EPOCHS =   35#@param {type: \"integer\"}\n",
        "BATCH_SIZE = 32#@param {type: \"integer\"}\n",
        "\n",
        "history = model.fit(train_data.shuffle(10000).batch(BATCH_SIZE),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_data.batch(BATCH_SIZE),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:27:39.664037Z",
          "iopub.status.busy": "2020-10-02T11:27:39.662923Z",
          "iopub.status.idle": "2020-10-02T11:27:39.665500Z",
          "shell.execute_reply": "2020-10-02T11:27:39.664859Z"
        },
        "id": "2sKE7kEyLJQZ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.set_facecolor('#F8F8F8')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:27:39.686233Z",
          "iopub.status.busy": "2020-10-02T11:27:39.683868Z",
          "iopub.status.idle": "2020-10-02T11:27:40.045154Z",
          "shell.execute_reply": "2020-10-02T11:27:40.045635Z"
        },
        "id": "nnQfxevhLKld"
      },
      "source": [
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjvtOw72Lpyw"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:27:40.051620Z",
          "iopub.status.busy": "2020-10-02T11:27:40.050525Z",
          "iopub.status.idle": "2020-10-02T11:27:40.225937Z",
          "shell.execute_reply": "2020-10-02T11:27:40.226363Z"
        },
        "id": "y0ExC8D0LX8m"
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print('%s: %.3f' % (name, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWp5OWeTL2EW"
      },
      "source": [
        "We can see that the loss quickly decreases while especially the accuracy rapidly increases. Let's plot some examples to check how the prediction relates to the true labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-02T11:27:40.233338Z",
          "iopub.status.busy": "2020-10-02T11:27:40.232295Z",
          "iopub.status.idle": "2020-10-02T11:27:40.451083Z",
          "shell.execute_reply": "2020-10-02T11:27:40.450480Z"
        },
        "id": "VzHzAOaaOVC0"
      },
      "source": [
        "prediction_dataset = next(iter(test_data.batch(20)))\n",
        "\n",
        "prediction_texts = [ex.numpy().decode('utf8') for ex in prediction_dataset[0]]\n",
        "prediction_labels = [label2str(x) for x in prediction_dataset[1]]\n",
        "\n",
        "predictions = [label2str(x) for x in model.predict_classes(prediction_texts)]\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    TEXT_FEATURE_NAME: prediction_texts,\n",
        "    LABEL_NAME: prediction_labels,\n",
        "    'prediction': predictions\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSGcrkE069_Q"
      },
      "source": [
        "We can see that for this random sample, the model predicts the correct label most of the times, indicating that it can embed scientific sentences pretty well."
      ]
    }
  ]
}